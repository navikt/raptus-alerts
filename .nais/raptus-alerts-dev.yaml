apiVersion: nais.io/v1
kind: Alert
metadata:
  name: raptus-alerts
  namespace: raptus
  labels:
    team: raptus
spec:
  receivers:
    slack:
      channel: '#team-raptus-alerts-dev'
  alerts:
    # Sjekker om en eller flere applikasjoner er nede i namespacet, dvs. at det ikke finnes noen kjørende podder
    - alert: Applikasjon er nede
      expr: kube_deployment_status_replicas_available{namespace="{{ namespace }}"} == 0
      for: 3m
      description: '*\{{ $labels.deployment }}* er nede i namespace \{{ $labels.namespace }}.'
      action: 'Kjør `kubectl describe pod -l app=\{{ $labels.deployment }} -n \{{ $labels.namespace }}` for å se events, og `kubectl logs -l app=\{{ $labels.deployment }} -n \{{ $labels.namespace }}` for logger. Sjekk også Kibana for eventuelle feil som er logget, query `application: \{{ $labels.deployment }} AND (level:Error OR level:Warning)`.'
      severity: danger
    # Sjekk HTTP 5xx-serverfeil
    - alert: Høy andel HTTP serverfeil (5xx-responser)
      expr: (100 * (sum by (service) (rate(nginx_ingress_controller_requests{status=~"^5\\d\\d", namespace="{{ namespace }}"}[3m])) / sum by (service) (rate(nginx_ingress_controller_requests{namespace="{{ namespace }}"}[3m])))) > 1
      for: 3m
      description: '*\{{ $labels.service }}* har logget mange feil.'
      action: 'Sjekk loggene for å se hvorfor \{{ $labels.service }} returnerer HTTP 5xx-feilresponser.'
      severity: danger
    # Sjekk HTTP 4xx-klientfeil. Filtrerer vekk stille perioder for å unngå falske alarmer
    - alert: Høy andel HTTP klientfeil (4xx-responser)
      expr: (100 * (sum by (service) (rate(nginx_ingress_controller_requests{status=~"^4\\d\\d", namespace="{{ namespace }}"}[3m])) / sum by (service) (rate(nginx_ingress_controller_requests{namespace="{{ namespace }}"}[3m])))) > 20 and (sum by (service) (rate(nginx_ingress_controller_requests{namespace="{{ namespace }}"}[3m]))) > 3
      for: 3m
      description: '*\{{ $labels.service }}* har logget mange feil.'
      action: 'Sjekk loggene for å se hvorfor \{{ $labels.service }} returnerer HTTP 4xx-feilresponser.'
      severity: warning
    # Sjekk hvorfor en pod starter unaturlig mange tråder
    - alert: Høy threadcount for en pod
      expr: sum(jvm_threads_live_threads{kubernetes_namespace="{{ namespace }}"}) by (kubernetes_pod_name, app) > 100
      for: 3m
      description: '*\{{ $labels.app }}* pod *\{{ $labels.kubernetes_pod_name }}* har startet unaturlig mange tråder.'
      action: 'Sjekk JVM metrics i NAIS App Dashboard for \{{ $labels.app }}. Lukkes f.eks. HTTP-klienten riktig?'
      severity: danger

